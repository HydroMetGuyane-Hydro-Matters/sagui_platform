version: "3.7"

volumes:
  postgresql_data:
  django_static_files:

secrets:
  pg_postgres_password:
    file: secrets-dev/pg_postgres_password.txt
  django_env:
    file: secrets-dev/django_env.txt
  django_superuser_password:
    file: secrets-dev/django_superuser_password.txt
  hydroweb_user:
    file: secrets-dev/hydroweb_user.txt
  hydroweb_password:
    file: secrets-dev/hydroweb_password.txt

services:
  database:
    image: postgis/postgis:14-3.2
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_DB=sagui
      - POSTGRES_PASSWORD_FILE=/run/secrets/pg_postgres_password
    volumes:
      - postgresql_data:/var/lib/postgresql/data
      - ./config/postgresql/entrypoint-initdb.d/:/docker-entrypoint-initdb.d
    secrets:
      - pg_postgres_password
    networks:
      - internal

  frontend:
    image: pigeosolutions/sagui-ui:latest
    restart: always
    expose:
      - 80
    networks:
      - internal

  backend:
    image: pigeosolutions/sagui_backend:latest
    restart: always
    build: ./sagui_backend
    depends_on:
      - database
    command: ["gunicorn", "--bind", "0.0.0.0:8000", "--log-level", "debug", "sagui_backend.wsgi:application"]
#    ports:
#      - 8000:8000
    expose:
      - 8000
    environment:
      - DJANGO_ENV_FILE=/run/secrets/django_env
      - DJANGO_SUPERUSER_PASSWORD_FILE=/run/secrets/django_superuser_password
      # Needed by wait-for-db:
      - POSTGRES_HOST=database
      - POSTGRES_PORT=5432
      - SAGUI_PATH_TO_ATMO_FILES=/atmo_s5p/data/styled
    volumes:
      - ./hyfaa-scheduler/work_configurations/operational_guyane_gsmap:/hyfaa-scheduler/data
      - ./atmo_s5p/data:/atmo_s5p/data
      - django_static_files:/static
    secrets:
      - django_env
      - django_superuser_password
    networks:
      - internal

  # serve django static files (gunicorn won't serve static files, not recommended)
  nginx:
    image: nginx:alpine
    depends_on:
      - backend
    volumes:
      - django_static_files:/usr/share/nginx/html/backend_static
      - ./atmo_s5p/data:/usr/share/nginx/html/backend_static/atmo
#      - ./nginx/templates:/etc/nginx/templates
    restart: always
    networks:
      - internal

  # This service is a fake one, it is only used for the build phase:
  # since pramsey did not push to dockerhub his alpine version
  # we need to build it locally, then we can use it as base image to build
  # our own image, pigeosolutions/pg_tileserv:latest
  pg-tileserv-base:
    image: pramsey/pg_tileserv:latest-alpine
    entrypoint: ["echo","Used only for build phase. Shutting down now"]
    restart: "no"
    build:
      context: ./pg_tileserv
      dockerfile: Dockerfile.alpine

  pg-tileserv:
    image: pigeosolutions/pg_tileserv:latest
    restart: always
    build:
      context: ./pg_tileserv/pigeosolutions
      dockerfile: Dockerfile.alpine.pigeo
    entrypoint: [ "/wait-for-db.sh" ]
    depends_on:
      - database
      - pg-tileserv-base
    env_file:
      - secrets-dev/pg_tileserv.env
    environment:
      - TS_BASEPATH=/tiles/
#    ports:
#      - 7800:7800
    expose:
      - 7800
    networks:
      - internal
#
#  frontend:
#    image: pigeosolutions/raincell-public
#    networks:
#      - internal

  varnish:
    image: varnish:stable
    volumes:
      - "./config/varnish/default.vcl:/etc/varnish/default.vcl"
#    ports:
#      - "80:80"
    expose:
      - 80
    tmpfs:
      - /var/lib/varnish:exec
    environment:
      - VARNISH_SIZE=50MB
    #    command: "-p default_keep=300"
    depends_on:
      - pg-tileserv
      - backend
      - frontend
    networks:
      - internal

  # Used for cron scripting: regular retrieval and processing of atmo data
  # start the scheduler as a ghost container (does nothing). It will make it easier to
  # call from a cron task (using exec, we have the whole process running in the console
  # as opposed to start which was restarting the task in the background
  atmo:
    image: pigeosolutions/sagui_atmo:latest
    build: atmo_s5p
    command: ["tail", "-f", "/dev/null"]
    user: $USER_ID:$GROUP_ID
    volumes:
      - ./atmo_s5p/data:/mnt/data
    restart: "no"
    networks:
      - internal

  # start the scheduler as a ghost container (does nothing). It will make it easier to
  # call from a cron task (using exec, we have the whole process running in the console
  # as opposed to start which was restarting the task in the background
  scheduler:
    restart: "no"
    image: pigeosolutions/hyfaa-scheduler:4.3
    command: ["tail", "-f", "/dev/null"]
    user: $USER_ID:$GROUP_ID
    build: ./hyfaa-scheduler
    secrets:
      - hydroweb_user
      - hydroweb_password
    environment:
      - HYDROWEB_USER_FILE=/run/secrets/hydroweb_user
      - HYDROWEB_PASSWORD_FILE=/run/secrets/hydroweb_password
    volumes:
      - ./hyfaa-scheduler/work_configurations/operational_guyane_gsmap:/work
    networks:
      - internal

networks:
  internal:
